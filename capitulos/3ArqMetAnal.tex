\chapter{Metodologia}\label{cap:metodologia}
Esta seção descreve a metodologia adotada para avaliação e testes da solução, apresentando o ambiente de desenvolvimento (\textit{software}, \textit{hardware} e modelos), bem como os procedimentos de validação funcional e a análise comparativa de eficiência.

\section{\textit{Software} e \textit{Hardware} Utilizados}
Os novos recursos e funcionalidades implementados diretamente na linguagem RL foram desenvolvidos com o auxílio das ferramentas Flex (versão 2.6.4) e Bison (versão 3.8.2), responsáveis por gerar os analisadores léxico e sintático do Robcmp. Além disso, a análise semântica foi escrita em C++ conforme a estrutura do compilador. Por outro lado, a nova biblioteca padrão foi desenvolvida com a própria linguagem RL, criando um arquivo \texttt{.rob} que continha todas as declarações das funções do \textit{wrapper} C do TFLM.

O ambiente de desenvolvimento foi o Visual Studio Code (versão 1.106.1), com o auxílio de duas extensões principais: o PlatformIO (versão 6.1.18), para depurar e exportar os \textit{firmwares} para as placas, e o RobCmpSyntax (versão 1.0), que fornece o realce de sintaxe para arquivos .rob. Além disso, para a validação dos experimentos, foram utilizados \textit{scripts} de automação (Makefiles personalizados) que padronizaram a execução dos testes unitários, garantindo que as flags de otimização (como \texttt{-Oz}) e linkedição fossem aplicadas consistentemente em todas as amostras comparativas.

A máquina de desenvolvimento utilizada foi um \textit{notebook} Lenovo IdeaPad 3 15ITL6, equipado com processador Intel® Core™ i7-1165G7, 16 GB de RAM e sistema operacional Ubuntu 24.04.1 LTS.
As validações funcionais e de eficiência foram realizadas nesta máquina, gerando binários compatíveis com a arquitetura \texttt{x86}.

% Além da máquina de desenvolvimento, a execução e validação das aplicações ocorreram em uma placa com o microcontrolador STM32F407VET6, da família STM32, popularmente chamada de Black STM32F407VET6. Essa placa conta com um processador ARM Cortex-M4 rodando a 168 MHz, 192 KB de RAM e 512 KB de memória Flash.

\section{Modelos de Machine Learning Adotados}
Para garantir a abrangência dos testes, foram selecionados diferentes modelos de TinyML, variando em complexidade e tipo de dado de entrada (numérico, texto, áudio e imagem). Todos os modelos foram selecionados do repositório do próprio TFLM no Github, com exceção do classificador de spam, que foi adquirido no site Kaggle, sendo um modelo disponibilizado pelo TensorFlow\footnote{\url{https://www.kaggle.com/models/tensorflow/spam-detection/tfLite}}. Os modelos utilizados são:

\begin{description}
    \item[Preditor de Seno:] O modelo ``Hello World'' do TinyML. É um modelo simples que tem como objetivo prever valores de uma onda senoidal com base em valores de entrada $x$ no intervalo de $0$ a $2\pi$.
    
    \item[Preditor de Seno Quantizado:] Uma variação do modelo anterior, porém submetido ao processo de quantização pós-treinamento. Seus pesos e ativações foram convertidos de ponto flutuante para inteiros (8 bits).

    \item[Classificador de Spam:] Esse classificador de spam é um modelo de Processamento de Linguagem Natural (NLP, do inglês \textit{Natural Language Processing}) que categoriza mensagens de texto como ``spam'' ou ``não spam''. Baixado do site Kaggle, é um modelo demonstrativo gerado pelo TensorFlow Lite Model Maker, treinado a partir de um arquivo de vocabulário contendo a lista de palavras e seus tokens equivalentes. Ele recebe como entrada um tensor de 20 inteiros (Int32) representando tokens de uma sentença codificada. Sua saída é um vetor de ponto flutuante (Float32) contendo duas probabilidades: a de ser spam e a de não ser.
    
    \item[Micro Speech:] O Micro Speech é CNN compacta ($<20$ kB) projetada para reconhecer as palavras-chave ``yes'' e ``no''. Ele opera em conjunto com um modelo pré-processador que converte amostras de áudio bruto ($16$ KHz) em espectrogramas compostos por 49 features. O classificador recebe esses dados como entrada e retorna as probabilidades para quatro categorias: silence, unknown, yes e no.

    \item[Person Detection:] Este é um modelo de detecção de pessoas que utiliza uma rede neural de aproximadamente 250 kB para reconhecer a presença humana. Ele recebe como entrada um tensor de inteiros de 8 bits (int8) contendo os dados brutos de uma imagem em escala de cinza. O modelo processa esse vetor e gera como saída pontuações (scores) que classificam a cena entre as categorias ``pessoa'' e ``não pessoa''.
\end{description}


\section{Procedimentos de Validação Funcional}
A etapa de validação funcional teve como objetivo verificar se a solução proposta cumpria o que prometia, sem levar em consideração sua eficiência, aplicabilidade, facilidade ou qualquer outro fator que mede sua qualidade.

Nesta etapa, as novas funcionalidades foram validadas utilizando testes unitários, que foram executados na máquina de desenvolvimento. Esses testes foram projetados para verificar se cada nova funcionalidade implementada no Robcmp estava operando conforme o esperado. Foram criados diversos arquivos \texttt{.rob} que utilizavam diferentes modelos de ML, abrangendo uma variedade de cenários e casos de uso. Os testes foram desenvolvidos utilizando apenas a biblioteca padrão ai.tflm disponibilizada pelo Robcmp, uma vez que as adaptações no \textit{frontend} do compilador não estavam totalmente integradas para a realização dos testes finais.

\section{Validação da eficiência e Análise Comparativa}
Para validar a eficiência da integração do TFLM à RL, foi realizada uma análise comparativa entre duas abordagens de desenvolvimento de \textit{firmwares}: os desenvolvidos com a biblioteca padrão do Robcmp para TinyML e os desenvolvidos diretamente em C++ utilizando o ambiente do TFLM. Nesta avaliação, foram considerados critérios como a facilidade de desenvolvimento, a manutenibilidade do código, o tempo de execução e o tamanho final do executável.

Para calcular o tempo de execução foi utilizada a ferramenta de \textit{benchmark} de linha de comando Hyperfine. Diferente do utilitário padrão \textit{time}, o Hyperfine automatiza a execução múltipla do binário para garantir relevância estatística, calculando a média e o desvio padrão dos tempos de execução. A ferramenta foi configurada para executar uma fase de aquecimento(\textit{warmup}) de 10 iterações antes da medição, visando mitigar a latência de I/O (leitura de disco) e estabilizar o uso de cache do processador. Em seguida foram realizadas 100 iterações de medição com o binário em questão para obter uma média confiável do tempo de execução.

Para atingir resultados verídicos, os binários foram executados isoladamente, sem outros processos concorrentes na máquina de desenvolvimento. O tempo de medição utilizado foi a média do tempo real de execução (\textit{Time (mean)}) fornecido pelo Hyperfine.